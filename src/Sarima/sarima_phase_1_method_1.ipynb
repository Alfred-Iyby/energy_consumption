{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmdarima\n",
      "  Downloading pmdarima-2.0.4-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (1.3.2)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima)\n",
      "  Downloading Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (1.12.0)\n",
      "Collecting statsmodels>=0.13.2 (from pmdarima)\n",
      "  Downloading statsmodels-0.14.2-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (2.2.1)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (65.5.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (3.3.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->pmdarima)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Downloading pmdarima-2.0.4-cp311-cp311-win_amd64.whl (614 kB)\n",
      "   ---------------------------------------- 0.0/614.7 kB ? eta -:--:--\n",
      "   --------------------------------------  614.4/614.7 kB 19.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 614.7/614.7 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading Cython-3.0.10-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.9/2.8 MB 61.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.8/2.8 MB 59.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 35.6 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.2-cp311-cp311-win_amd64.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.7/9.9 MB 36.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/9.9 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.2/9.9 MB 38.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.0/9.9 MB 31.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.5/9.9 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 29.9 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 233.9/233.9 kB 14.0 MB/s eta 0:00:00\n",
      "Installing collected packages: patsy, Cython, statsmodels, pmdarima\n",
      "Successfully installed Cython-3.0.10 patsy-0.5.6 pmdarima-2.0.4 statsmodels-0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SARIMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Processing ID: Exp_553\n",
      "2 Processing ID: Exp_401\n",
      "3 Processing ID: Exp_266\n",
      "4 Processing ID: Exp_62\n",
      "5 Processing ID: Exp_111\n",
      "6 Processing ID: Exp_567\n",
      "7 Processing ID: Exp_570\n",
      "8 Processing ID: Exp_500\n",
      "9 Processing ID: Exp_52\n",
      "10 Processing ID: Exp_222\n",
      "11 Processing ID: Exp_587\n",
      "12 Processing ID: Exp_17\n",
      "13 Processing ID: Exp_462\n",
      "14 Processing ID: Exp_271\n",
      "15 Processing ID: Exp_49\n",
      "16 Processing ID: Exp_451\n",
      "17 Processing ID: Exp_502\n",
      "18 Processing ID: Exp_86\n",
      "19 Processing ID: Exp_612\n",
      "20 Processing ID: Exp_509\n",
      "21 Processing ID: Exp_12\n",
      "22 Processing ID: Exp_208\n",
      "23 Processing ID: Exp_529\n",
      "24 Processing ID: Exp_128\n",
      "25 Processing ID: Exp_56\n",
      "26 Processing ID: Exp_635\n",
      "27 Processing ID: Exp_93\n",
      "28 Processing ID: Exp_313\n",
      "29 Processing ID: Exp_446\n",
      "30 Processing ID: Exp_643\n",
      "31 Processing ID: Exp_223\n",
      "32 Processing ID: Exp_315\n",
      "33 Processing ID: Exp_649\n",
      "34 Processing ID: Exp_191\n",
      "35 Processing ID: Exp_445\n",
      "36 Processing ID: Exp_518\n",
      "37 Processing ID: Exp_365\n",
      "38 Processing ID: Exp_356\n",
      "39 Processing ID: Exp_420\n",
      "40 Processing ID: Exp_547\n",
      "41 Processing ID: Exp_103\n",
      "42 Processing ID: Exp_690\n",
      "43 Processing ID: Exp_693\n",
      "44 Processing ID: Exp_367\n",
      "45 Processing ID: Exp_325\n",
      "46 Processing ID: Exp_182\n",
      "47 Processing ID: Exp_124\n",
      "48 Processing ID: Exp_272\n",
      "49 Processing ID: Exp_332\n",
      "50 Processing ID: Exp_732\n",
      "51 Processing ID: Exp_733\n",
      "52 Processing ID: Exp_737\n",
      "53 Processing ID: Exp_23\n",
      "54 Processing ID: Exp_460\n",
      "Overall MSE: 0.9566387555388245\n",
      "Overall MAE: 0.6657383634178143\n",
      "Overall RMSE: 0.9780791151736267\n",
      "Forecast results have been written to forecast_results_2_8020.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load your dataset (assuming it is a CSV file)\n",
    "df = pd.read_csv('phase1_only_records.csv')\n",
    "\n",
    "# Convert 'Date' and 'Hour' columns to a datetime object\n",
    "df['Datetime'] = pd.to_datetime(df['Date']) + pd.to_timedelta(df['Hour'], unit='h')\n",
    "\n",
    "# Set 'Datetime' as index\n",
    "df.set_index('Datetime', inplace=True)\n",
    "exog_vars = ['Temperature']\n",
    "\n",
    "# Prepare a function to fit and forecast using auto_arima for each ID in chunks\n",
    "def fit_forecast_sarima(df, split_ratio=0.8, chunk_size=50):\n",
    "    ids = df['ID'].unique()\n",
    "    forecasts = []\n",
    "    \n",
    "    for chunk_start in range(0, len(ids), chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, len(ids))\n",
    "        chunk_ids = ids[chunk_start:chunk_end]\n",
    "        \n",
    "        for i, id_ in enumerate(chunk_ids, start=chunk_start+1):\n",
    "            print(f\"{i} Processing ID: {id_}\")\n",
    "            df_id = df[df['ID'] == id_].sort_index()\n",
    "\n",
    "            # Split the data into train and test\n",
    "            split_index = int(len(df_id) * split_ratio)\n",
    "            train = df_id.iloc[:split_index]\n",
    "            test = df_id.iloc[split_index:]\n",
    "\n",
    "            # Fit the auto_arima model\n",
    "            model = auto_arima(train['Demand_kWh'],\n",
    "                               exogenous=train[exog_vars],\n",
    "                               seasonal=True,\n",
    "                               m=24,  # Assuming daily seasonality with hourly data\n",
    "                               stepwise=True,\n",
    "                               suppress_warnings=True,\n",
    "                               trace=False,\n",
    "                               max_p=2, max_q=2, max_P=1, max_Q=1, max_order=5)\n",
    "\n",
    "            # Forecast\n",
    "            n_periods = len(test)\n",
    "            forecast = model.predict(n_periods=n_periods, exogenous=test[exog_vars])\n",
    "\n",
    "            # Store the forecast and actual values\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'ID': id_,\n",
    "                'Datetime': test.index,\n",
    "                'Actual_Demand': test['Demand_kWh'],\n",
    "                'Predicted_Demand': forecast\n",
    "            })\n",
    "\n",
    "            forecasts.append(forecast_df)\n",
    "            \n",
    "        # Run garbage collection to free memory\n",
    "        gc.collect()\n",
    "    \n",
    "    return pd.concat(forecasts)\n",
    "\n",
    "# Run the forecasting function\n",
    "results_df = fit_forecast_sarima(df)\n",
    "\n",
    "# Calculate overall error metrics\n",
    "mse = mean_squared_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "mae = mean_absolute_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Overall MSE: {mse}\")\n",
    "print(f\"Overall MAE: {mae}\")\n",
    "print(f\"Overall RMSE: {rmse}\")\n",
    "\n",
    "# Write the results to a file\n",
    "results_df['Date'] = results_df['Datetime'].dt.date\n",
    "results_df['Hour'] = results_df['Datetime'].dt.hour\n",
    "results_df = results_df[['ID', 'Date', 'Hour', 'Actual_Demand', 'Predicted_Demand']]\n",
    "results_df.to_csv('sarima_results_1_8020.csv', index=False)\n",
    "\n",
    "print(\"Forecast results have been written to forecast_results_2_8020.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Processing ID: Exp_553\n",
      "2 Processing ID: Exp_401\n",
      "3 Processing ID: Exp_266\n",
      "4 Processing ID: Exp_62\n",
      "5 Processing ID: Exp_111\n",
      "6 Processing ID: Exp_567\n",
      "7 Processing ID: Exp_570\n",
      "8 Processing ID: Exp_500\n",
      "9 Processing ID: Exp_52\n",
      "10 Processing ID: Exp_222\n",
      "11 Processing ID: Exp_587\n",
      "12 Processing ID: Exp_17\n",
      "13 Processing ID: Exp_462\n",
      "14 Processing ID: Exp_271\n",
      "15 Processing ID: Exp_49\n",
      "16 Processing ID: Exp_451\n",
      "17 Processing ID: Exp_502\n",
      "18 Processing ID: Exp_86\n",
      "19 Processing ID: Exp_612\n",
      "20 Processing ID: Exp_509\n",
      "21 Processing ID: Exp_12\n",
      "22 Processing ID: Exp_208\n",
      "23 Processing ID: Exp_529\n",
      "24 Processing ID: Exp_128\n",
      "25 Processing ID: Exp_56\n",
      "26 Processing ID: Exp_635\n",
      "27 Processing ID: Exp_93\n",
      "28 Processing ID: Exp_313\n",
      "29 Processing ID: Exp_446\n",
      "30 Processing ID: Exp_643\n",
      "31 Processing ID: Exp_223\n",
      "32 Processing ID: Exp_315\n",
      "33 Processing ID: Exp_649\n",
      "34 Processing ID: Exp_191\n",
      "35 Processing ID: Exp_445\n",
      "36 Processing ID: Exp_518\n",
      "37 Processing ID: Exp_365\n",
      "38 Processing ID: Exp_356\n",
      "39 Processing ID: Exp_420\n",
      "40 Processing ID: Exp_547\n",
      "41 Processing ID: Exp_103\n",
      "42 Processing ID: Exp_690\n",
      "43 Processing ID: Exp_693\n",
      "44 Processing ID: Exp_367\n",
      "45 Processing ID: Exp_325\n",
      "46 Processing ID: Exp_182\n",
      "47 Processing ID: Exp_124\n",
      "48 Processing ID: Exp_272\n",
      "49 Processing ID: Exp_332\n",
      "50 Processing ID: Exp_732\n",
      "51 Processing ID: Exp_733\n",
      "52 Processing ID: Exp_737\n",
      "53 Processing ID: Exp_23\n",
      "54 Processing ID: Exp_460\n",
      "Overall MSE: 1.017054522655143\n",
      "Overall MAE: 0.6878280430016195\n",
      "Overall RMSE: 1.0084912109954867\n",
      "Forecast results have been written to forecast_results_2_8020.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load your dataset (assuming it is a CSV file)\n",
    "df = pd.read_csv('phase1_only_records.csv')\n",
    "\n",
    "# Convert 'Date' and 'Hour' columns to a datetime object\n",
    "df['Datetime'] = pd.to_datetime(df['Date']) + pd.to_timedelta(df['Hour'], unit='h')\n",
    "\n",
    "# Set 'Datetime' as index\n",
    "df.set_index('Datetime', inplace=True)\n",
    "exog_vars = ['Temperature']\n",
    "\n",
    "# Prepare a function to fit and forecast using auto_arima for each ID in chunks\n",
    "def fit_forecast_sarima(df, split_ratio=0.75, chunk_size=50):\n",
    "    ids = df['ID'].unique()\n",
    "    forecasts = []\n",
    "    \n",
    "    for chunk_start in range(0, len(ids), chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, len(ids))\n",
    "        chunk_ids = ids[chunk_start:chunk_end]\n",
    "        \n",
    "        for i, id_ in enumerate(chunk_ids, start=chunk_start+1):\n",
    "            print(f\"{i} Processing ID: {id_}\")\n",
    "            df_id = df[df['ID'] == id_].sort_index()\n",
    "\n",
    "            # Split the data into train and test\n",
    "            split_index = int(len(df_id) * split_ratio)\n",
    "            train = df_id.iloc[:split_index]\n",
    "            test = df_id.iloc[split_index:]\n",
    "\n",
    "            # Fit the auto_arima model\n",
    "            model = auto_arima(train['Demand_kWh'],\n",
    "                               exogenous=train[exog_vars],\n",
    "                               seasonal=True,\n",
    "                               m=24,  # Assuming daily seasonality with hourly data\n",
    "                               stepwise=True,\n",
    "                               suppress_warnings=True,\n",
    "                               trace=False,\n",
    "                               max_p=2, max_q=2, max_P=1, max_Q=1, max_order=5)\n",
    "\n",
    "            # Forecast\n",
    "            n_periods = len(test)\n",
    "            forecast = model.predict(n_periods=n_periods, exogenous=test[exog_vars])\n",
    "\n",
    "            # Store the forecast and actual values\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'ID': id_,\n",
    "                'Datetime': test.index,\n",
    "                'Actual_Demand': test['Demand_kWh'],\n",
    "                'Predicted_Demand': forecast\n",
    "            })\n",
    "\n",
    "            forecasts.append(forecast_df)\n",
    "            \n",
    "        # Run garbage collection to free memory\n",
    "        gc.collect()\n",
    "    \n",
    "    return pd.concat(forecasts)\n",
    "\n",
    "# Run the forecasting function\n",
    "results_df = fit_forecast_sarima(df)\n",
    "\n",
    "# Calculate overall error metrics\n",
    "mse = mean_squared_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "mae = mean_absolute_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Overall MSE: {mse}\")\n",
    "print(f\"Overall MAE: {mae}\")\n",
    "print(f\"Overall RMSE: {rmse}\")\n",
    "\n",
    "# Write the results to a file\n",
    "results_df['Date'] = results_df['Datetime'].dt.date\n",
    "results_df['Hour'] = results_df['Datetime'].dt.hour\n",
    "results_df = results_df[['ID', 'Date', 'Hour', 'Actual_Demand', 'Predicted_Demand']]\n",
    "results_df.to_csv('sarima_results_1_7525.csv', index=False)\n",
    "\n",
    "print(\"Forecast results have been written to forecast_results_2_8020.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Processing ID: Exp_553\n",
      "2 Processing ID: Exp_401\n",
      "3 Processing ID: Exp_266\n",
      "4 Processing ID: Exp_62\n",
      "5 Processing ID: Exp_111\n",
      "6 Processing ID: Exp_567\n",
      "7 Processing ID: Exp_570\n",
      "8 Processing ID: Exp_500\n",
      "9 Processing ID: Exp_52\n",
      "10 Processing ID: Exp_222\n",
      "11 Processing ID: Exp_587\n",
      "12 Processing ID: Exp_17\n",
      "13 Processing ID: Exp_462\n",
      "14 Processing ID: Exp_271\n",
      "15 Processing ID: Exp_49\n",
      "16 Processing ID: Exp_451\n",
      "17 Processing ID: Exp_502\n",
      "18 Processing ID: Exp_86\n",
      "19 Processing ID: Exp_612\n",
      "20 Processing ID: Exp_509\n",
      "21 Processing ID: Exp_12\n",
      "22 Processing ID: Exp_208\n",
      "23 Processing ID: Exp_529\n",
      "24 Processing ID: Exp_128\n",
      "25 Processing ID: Exp_56\n",
      "26 Processing ID: Exp_635\n",
      "27 Processing ID: Exp_93\n",
      "28 Processing ID: Exp_313\n",
      "29 Processing ID: Exp_446\n",
      "30 Processing ID: Exp_643\n",
      "31 Processing ID: Exp_223\n",
      "32 Processing ID: Exp_315\n",
      "33 Processing ID: Exp_649\n",
      "34 Processing ID: Exp_191\n",
      "35 Processing ID: Exp_445\n",
      "36 Processing ID: Exp_518\n",
      "37 Processing ID: Exp_365\n",
      "38 Processing ID: Exp_356\n",
      "39 Processing ID: Exp_420\n",
      "40 Processing ID: Exp_547\n",
      "41 Processing ID: Exp_103\n",
      "42 Processing ID: Exp_690\n",
      "43 Processing ID: Exp_693\n",
      "44 Processing ID: Exp_367\n",
      "45 Processing ID: Exp_325\n",
      "46 Processing ID: Exp_182\n",
      "47 Processing ID: Exp_124\n",
      "48 Processing ID: Exp_272\n",
      "49 Processing ID: Exp_332\n",
      "50 Processing ID: Exp_732\n",
      "51 Processing ID: Exp_733\n",
      "52 Processing ID: Exp_737\n",
      "53 Processing ID: Exp_23\n",
      "54 Processing ID: Exp_460\n",
      "Overall MSE: 0.9313769956053473\n",
      "Overall MAE: 0.6308930602125443\n",
      "Overall RMSE: 0.9650787509863364\n",
      "Forecast results have been written to forecast_results_2_8020.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load your dataset (assuming it is a CSV file)\n",
    "df = pd.read_csv('phase1_only_records.csv')\n",
    "\n",
    "# Convert 'Date' and 'Hour' columns to a datetime object\n",
    "df['Datetime'] = pd.to_datetime(df['Date']) + pd.to_timedelta(df['Hour'], unit='h')\n",
    "\n",
    "# Set 'Datetime' as index\n",
    "df.set_index('Datetime', inplace=True)\n",
    "exog_vars = ['Temperature']\n",
    "\n",
    "# Prepare a function to fit and forecast using auto_arima for each ID in chunks\n",
    "def fit_forecast_sarima(df, split_ratio=0.5, chunk_size=50):\n",
    "    ids = df['ID'].unique()\n",
    "    forecasts = []\n",
    "    \n",
    "    for chunk_start in range(0, len(ids), chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, len(ids))\n",
    "        chunk_ids = ids[chunk_start:chunk_end]\n",
    "        \n",
    "        for i, id_ in enumerate(chunk_ids, start=chunk_start+1):\n",
    "            print(f\"{i} Processing ID: {id_}\")\n",
    "            df_id = df[df['ID'] == id_].sort_index()\n",
    "\n",
    "            # Split the data into train and test\n",
    "            split_index = int(len(df_id) * split_ratio)\n",
    "            train = df_id.iloc[:split_index]\n",
    "            test = df_id.iloc[split_index:]\n",
    "\n",
    "            # Fit the auto_arima model\n",
    "            model = auto_arima(train['Demand_kWh'],\n",
    "                               exogenous=train[exog_vars],\n",
    "                               seasonal=True,\n",
    "                               m=24,  # Assuming daily seasonality with hourly data\n",
    "                               stepwise=True,\n",
    "                               suppress_warnings=True,\n",
    "                               trace=False,\n",
    "                               )\n",
    "\n",
    "            # Forecast\n",
    "            n_periods = len(test)\n",
    "            forecast = model.predict(n_periods=n_periods, exogenous=test[exog_vars])\n",
    "\n",
    "            # Store the forecast and actual values\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'ID': id_,\n",
    "                'Datetime': test.index,\n",
    "                'Actual_Demand': test['Demand_kWh'],\n",
    "                'Predicted_Demand': forecast\n",
    "            })\n",
    "\n",
    "            forecasts.append(forecast_df)\n",
    "            \n",
    "        # Run garbage collection to free memory\n",
    "        gc.collect()\n",
    "    \n",
    "    return pd.concat(forecasts)\n",
    "\n",
    "# Run the forecasting function\n",
    "results_df = fit_forecast_sarima(df)\n",
    "\n",
    "# Calculate overall error metrics\n",
    "mse = mean_squared_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "mae = mean_absolute_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Overall MSE: {mse}\")\n",
    "print(f\"Overall MAE: {mae}\")\n",
    "print(f\"Overall RMSE: {rmse}\")\n",
    "\n",
    "# Write the results to a file\n",
    "results_df['Date'] = results_df['Datetime'].dt.date\n",
    "results_df['Hour'] = results_df['Datetime'].dt.hour\n",
    "results_df = results_df[['ID', 'Date', 'Hour', 'Actual_Demand', 'Predicted_Demand']]\n",
    "results_df.to_csv('sarima_results_1_5050.csv', index=False)\n",
    "\n",
    "print(\"Forecast results have been written to forecast_results_2_8020.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Processing ID: Exp_3928\n",
      "2 Processing ID: Exp_3903\n",
      "3 Processing ID: Exp_3921\n",
      "4 Processing ID: Exp_3844\n",
      "5 Processing ID: Exp_3911\n",
      "6 Processing ID: Exp_3913\n",
      "7 Processing ID: Exp_3896\n",
      "8 Processing ID: Exp_3922\n",
      "9 Processing ID: Exp_3919\n",
      "10 Processing ID: Exp_3891\n",
      "11 Processing ID: Exp_3917\n",
      "12 Processing ID: Exp_3858\n",
      "13 Processing ID: Exp_3884\n",
      "14 Processing ID: Exp_3900\n",
      "15 Processing ID: Exp_3934\n",
      "16 Processing ID: Exp_3904\n",
      "17 Processing ID: Exp_3901\n",
      "18 Processing ID: Exp_3868\n",
      "19 Processing ID: Exp_3889\n",
      "20 Processing ID: Exp_3920\n",
      "21 Processing ID: Exp_3867\n",
      "22 Processing ID: Exp_3931\n",
      "23 Processing ID: Exp_3880\n",
      "24 Processing ID: Exp_3895\n",
      "25 Processing ID: Exp_3860\n",
      "26 Processing ID: Exp_3843\n",
      "27 Processing ID: Exp_3873\n",
      "28 Processing ID: Exp_3914\n",
      "29 Processing ID: Exp_3883\n",
      "30 Processing ID: Exp_3871\n",
      "31 Processing ID: Exp_3924\n",
      "32 Processing ID: Exp_3929\n",
      "33 Processing ID: Exp_3837\n",
      "34 Processing ID: Exp_3912\n",
      "35 Processing ID: Exp_3935\n",
      "36 Processing ID: Exp_3874\n",
      "37 Processing ID: Exp_3877\n",
      "38 Processing ID: Exp_3887\n",
      "39 Processing ID: Exp_3866\n",
      "40 Processing ID: Exp_3841\n",
      "41 Processing ID: Exp_3902\n",
      "42 Processing ID: Exp_3869\n",
      "43 Processing ID: Exp_3850\n",
      "44 Processing ID: Exp_3886\n",
      "45 Processing ID: Exp_3865\n",
      "46 Processing ID: Exp_3915\n",
      "47 Processing ID: Exp_3885\n",
      "48 Processing ID: Exp_3875\n",
      "49 Processing ID: Exp_3882\n",
      "50 Processing ID: Exp_3847\n",
      "51 Processing ID: Exp_3930\n",
      "52 Processing ID: Exp_3906\n",
      "53 Processing ID: Exp_3932\n",
      "54 Processing ID: Exp_3892\n",
      "55 Processing ID: Exp_3879\n",
      "56 Processing ID: Exp_3909\n",
      "57 Processing ID: Exp_3890\n",
      "58 Processing ID: Exp_3855\n",
      "59 Processing ID: Exp_3854\n",
      "60 Processing ID: Exp_3851\n",
      "61 Processing ID: Exp_3936\n",
      "62 Processing ID: Exp_3853\n",
      "63 Processing ID: Exp_3872\n",
      "64 Processing ID: Exp_3849\n",
      "65 Processing ID: Exp_3878\n",
      "66 Processing ID: Exp_3893\n",
      "67 Processing ID: Exp_3876\n",
      "68 Processing ID: Exp_3898\n",
      "69 Processing ID: Exp_3923\n",
      "70 Processing ID: Exp_3927\n",
      "71 Processing ID: Exp_3839\n",
      "72 Processing ID: Exp_3938\n",
      "73 Processing ID: Exp_3899\n",
      "74 Processing ID: Exp_3881\n",
      "75 Processing ID: Exp_3933\n",
      "76 Processing ID: Exp_3910\n",
      "77 Processing ID: Exp_3862\n",
      "78 Processing ID: Exp_3908\n",
      "79 Processing ID: Exp_3863\n",
      "80 Processing ID: Exp_3840\n",
      "81 Processing ID: Exp_3888\n",
      "82 Processing ID: Exp_3967\n",
      "83 Processing ID: Exp_3859\n",
      "84 Processing ID: Exp_3907\n",
      "85 Processing ID: Exp_3926\n",
      "86 Processing ID: Exp_3916\n",
      "87 Processing ID: Exp_3870\n",
      "88 Processing ID: Exp_3894\n",
      "89 Processing ID: Exp_3958\n",
      "90 Processing ID: Exp_3918\n",
      "91 Processing ID: Exp_3852\n",
      "92 Processing ID: Exp_3937\n",
      "93 Processing ID: Exp_3857\n",
      "94 Processing ID: Exp_3838\n",
      "95 Processing ID: Exp_3842\n",
      "96 Processing ID: Exp_3974\n",
      "97 Processing ID: Exp_3949\n",
      "98 Processing ID: Exp_3972\n",
      "99 Processing ID: Exp_3952\n",
      "100 Processing ID: Exp_3846\n",
      "101 Processing ID: Exp_3864\n",
      "102 Processing ID: Exp_3848\n",
      "103 Processing ID: Exp_3845\n",
      "104 Processing ID: Exp_3897\n",
      "105 Processing ID: Exp_3939\n",
      "106 Processing ID: Exp_3975\n",
      "107 Processing ID: Exp_3905\n",
      "108 Processing ID: Exp_3856\n",
      "109 Processing ID: Exp_3941\n",
      "110 Processing ID: Exp_3925\n",
      "111 Processing ID: Exp_3861\n",
      "112 Processing ID: Exp_3229\n",
      "113 Processing ID: Exp_3194\n",
      "114 Processing ID: Exp_3218\n",
      "115 Processing ID: Exp_3210\n",
      "116 Processing ID: Exp_3156\n",
      "117 Processing ID: Exp_3248\n",
      "118 Processing ID: Exp_3271\n",
      "119 Processing ID: Exp_3242\n",
      "120 Processing ID: Exp_3258\n",
      "121 Processing ID: Exp_3255\n",
      "122 Processing ID: Exp_3204\n",
      "123 Processing ID: Exp_3188\n",
      "124 Processing ID: Exp_3168\n",
      "125 Processing ID: Exp_3250\n",
      "126 Processing ID: Exp_3153\n",
      "127 Processing ID: Exp_3185\n",
      "128 Processing ID: Exp_3247\n",
      "129 Processing ID: Exp_3233\n",
      "130 Processing ID: Exp_3157\n",
      "131 Processing ID: Exp_3169\n",
      "132 Processing ID: Exp_3249\n",
      "133 Processing ID: Exp_3219\n",
      "134 Processing ID: Exp_3161\n",
      "135 Processing ID: Exp_3296\n",
      "136 Processing ID: Exp_3206\n",
      "137 Processing ID: Exp_3290\n",
      "138 Processing ID: Exp_3239\n",
      "139 Processing ID: Exp_3177\n",
      "140 Processing ID: Exp_3181\n",
      "141 Processing ID: Exp_3186\n",
      "142 Processing ID: Exp_3292\n",
      "143 Processing ID: Exp_3259\n",
      "144 Processing ID: Exp_3176\n",
      "145 Processing ID: Exp_3287\n",
      "146 Processing ID: Exp_3263\n",
      "147 Processing ID: Exp_3152\n",
      "148 Processing ID: Exp_3253\n",
      "149 Processing ID: Exp_3224\n",
      "150 Processing ID: Exp_3151\n",
      "151 Processing ID: Exp_3295\n",
      "152 Processing ID: Exp_3174\n",
      "153 Processing ID: Exp_3190\n",
      "154 Processing ID: Exp_3209\n",
      "155 Processing ID: Exp_3192\n",
      "156 Processing ID: Exp_3155\n",
      "157 Processing ID: Exp_3202\n",
      "158 Processing ID: Exp_3217\n",
      "159 Processing ID: Exp_3298\n",
      "160 Processing ID: Exp_3203\n",
      "161 Processing ID: Exp_3228\n",
      "162 Processing ID: Exp_3211\n",
      "163 Processing ID: Exp_3223\n",
      "164 Processing ID: Exp_3173\n",
      "165 Processing ID: Exp_3167\n",
      "166 Processing ID: Exp_3189\n",
      "167 Processing ID: Exp_3251\n",
      "168 Processing ID: Exp_3257\n",
      "169 Processing ID: Exp_3197\n",
      "170 Processing ID: Exp_3213\n",
      "171 Processing ID: Exp_3214\n",
      "172 Processing ID: Exp_3231\n",
      "173 Processing ID: Exp_3226\n",
      "174 Processing ID: Exp_3162\n",
      "175 Processing ID: Exp_3154\n",
      "176 Processing ID: Exp_3183\n",
      "177 Processing ID: Exp_3227\n",
      "178 Processing ID: Exp_3180\n",
      "179 Processing ID: Exp_3225\n",
      "180 Processing ID: Exp_3232\n",
      "181 Processing ID: Exp_3244\n",
      "182 Processing ID: Exp_3187\n",
      "183 Processing ID: Exp_3201\n",
      "184 Processing ID: Exp_3166\n",
      "185 Processing ID: Exp_3289\n",
      "186 Processing ID: Exp_3172\n",
      "187 Processing ID: Exp_3260\n",
      "188 Processing ID: Exp_3179\n",
      "189 Processing ID: Exp_3293\n",
      "190 Processing ID: Exp_3294\n",
      "191 Processing ID: Exp_3288\n",
      "192 Processing ID: Exp_3245\n",
      "193 Processing ID: Exp_3200\n",
      "194 Processing ID: Exp_3262\n",
      "195 Processing ID: Exp_3238\n",
      "196 Processing ID: Exp_3415\n",
      "197 Processing ID: Exp_3418\n",
      "198 Processing ID: Exp_3304\n",
      "199 Processing ID: Exp_3300\n",
      "200 Processing ID: Exp_3277\n",
      "201 Processing ID: Exp_3416\n",
      "202 Processing ID: Exp_3316\n",
      "203 Processing ID: Exp_3417\n",
      "204 Processing ID: Exp_3358\n",
      "205 Processing ID: Exp_3379\n",
      "206 Processing ID: Exp_3375\n",
      "207 Processing ID: Exp_3373\n",
      "208 Processing ID: Exp_3382\n",
      "209 Processing ID: Exp_3184\n",
      "210 Processing ID: Exp_3158\n",
      "211 Processing ID: Exp_3401\n",
      "212 Processing ID: Exp_3356\n",
      "213 Processing ID: Exp_3306\n",
      "214 Processing ID: Exp_3387\n",
      "215 Processing ID: Exp_3398\n",
      "216 Processing ID: Exp_3267\n",
      "217 Processing ID: Exp_3222\n",
      "218 Processing ID: Exp_3380\n",
      "219 Processing ID: Exp_3365\n",
      "220 Processing ID: Exp_3182\n",
      "221 Processing ID: Exp_3280\n",
      "222 Processing ID: Exp_3374\n",
      "223 Processing ID: Exp_3359\n",
      "224 Processing ID: Exp_3376\n",
      "225 Processing ID: Exp_3355\n",
      "226 Processing ID: Exp_3363\n",
      "227 Processing ID: Exp_3402\n",
      "228 Processing ID: Exp_3266\n",
      "229 Processing ID: Exp_3403\n",
      "230 Processing ID: Exp_3378\n",
      "231 Processing ID: Exp_3400\n",
      "232 Processing ID: Exp_3367\n",
      "233 Processing ID: Exp_3372\n",
      "234 Processing ID: Exp_3377\n",
      "235 Processing ID: Exp_3389\n",
      "236 Processing ID: Exp_3268\n",
      "237 Processing ID: Exp_3386\n",
      "238 Processing ID: Exp_3364\n",
      "239 Processing ID: Exp_3317\n",
      "240 Processing ID: Exp_3385\n",
      "241 Processing ID: Exp_3274\n",
      "242 Processing ID: Exp_3269\n",
      "243 Processing ID: Exp_3270\n",
      "244 Processing ID: Exp_3276\n",
      "245 Processing ID: Exp_3272\n",
      "246 Processing ID: Exp_3307\n",
      "247 Processing ID: Exp_3394\n",
      "248 Processing ID: Exp_3361\n",
      "249 Processing ID: Exp_3366\n",
      "250 Processing ID: Exp_3275\n",
      "251 Processing ID: Exp_3393\n",
      "252 Processing ID: Exp_3397\n",
      "253 Processing ID: Exp_3396\n",
      "254 Processing ID: Exp_3395\n",
      "255 Processing ID: Exp_3368\n",
      "256 Processing ID: Exp_3405\n",
      "257 Processing ID: Exp_3404\n",
      "258 Processing ID: Exp_3399\n",
      "259 Processing ID: Exp_3309\n",
      "260 Processing ID: Exp_3264\n",
      "261 Processing ID: Exp_3342\n",
      "262 Processing ID: Exp_3334\n",
      "263 Processing ID: Exp_3329\n",
      "264 Processing ID: Exp_3319\n",
      "265 Processing ID: Exp_3332\n",
      "266 Processing ID: Exp_3338\n",
      "267 Processing ID: Exp_3340\n",
      "268 Processing ID: Exp_3346\n",
      "269 Processing ID: Exp_3344\n",
      "270 Processing ID: Exp_3325\n",
      "271 Processing ID: Exp_3327\n",
      "272 Processing ID: Exp_3323\n",
      "273 Processing ID: Exp_3326\n",
      "274 Processing ID: Exp_3330\n",
      "275 Processing ID: Exp_3333\n",
      "276 Processing ID: Exp_3339\n",
      "277 Processing ID: Exp_3343\n",
      "278 Processing ID: Exp_3322\n",
      "279 Processing ID: Exp_3324\n",
      "280 Processing ID: Exp_3341\n",
      "281 Processing ID: Exp_3301\n",
      "282 Processing ID: Exp_3336\n",
      "283 Processing ID: Exp_3321\n",
      "284 Processing ID: Exp_3318\n",
      "285 Processing ID: Exp_3345\n",
      "286 Processing ID: Exp_3337\n",
      "287 Processing ID: Exp_3347\n",
      "288 Processing ID: Exp_3411\n",
      "289 Processing ID: Exp_3285\n",
      "290 Processing ID: Exp_3281\n",
      "291 Processing ID: Exp_3406\n",
      "292 Processing ID: Exp_3412\n",
      "293 Processing ID: Exp_3409\n",
      "294 Processing ID: Exp_3390\n",
      "295 Processing ID: Exp_3391\n",
      "296 Processing ID: Exp_3349\n",
      "297 Processing ID: Exp_3419\n",
      "298 Processing ID: Exp_3310\n",
      "299 Processing ID: Exp_3408\n",
      "300 Processing ID: Exp_3410\n",
      "301 Processing ID: Exp_3282\n",
      "302 Processing ID: Exp_3283\n",
      "303 Processing ID: Exp_3351\n",
      "304 Processing ID: Exp_3284\n",
      "305 Processing ID: Exp_3312\n",
      "306 Processing ID: Exp_3279\n",
      "307 Processing ID: Exp_3241\n",
      "308 Processing ID: Exp_3196\n",
      "309 Processing ID: Exp_3392\n",
      "310 Processing ID: Exp_3165\n",
      "311 Processing ID: Exp_3331\n",
      "312 Processing ID: Exp_3302\n",
      "313 Processing ID: Exp_3313\n",
      "314 Processing ID: Exp_3308\n",
      "315 Processing ID: Exp_3383\n",
      "316 Processing ID: Exp_3195\n",
      "317 Processing ID: Exp_3230\n",
      "318 Processing ID: Exp_3315\n",
      "319 Processing ID: Exp_3370\n",
      "320 Processing ID: Exp_3164\n",
      "321 Processing ID: Exp_3328\n",
      "322 Processing ID: Exp_3384\n",
      "323 Processing ID: Exp_3305\n",
      "324 Processing ID: Exp_3175\n",
      "325 Processing ID: Exp_3193\n",
      "326 Processing ID: Exp_3237\n",
      "327 Processing ID: Exp_3215\n",
      "328 Processing ID: Exp_3311\n",
      "329 Processing ID: Exp_3150\n",
      "330 Processing ID: Exp_3159\n",
      "331 Processing ID: Exp_3381\n",
      "332 Processing ID: Exp_3303\n",
      "333 Processing ID: Exp_3216\n",
      "334 Processing ID: Exp_3352\n",
      "335 Processing ID: Exp_3357\n",
      "336 Processing ID: Exp_3236\n",
      "337 Processing ID: Exp_3208\n",
      "338 Processing ID: Exp_3354\n",
      "339 Processing ID: Exp_3212\n",
      "340 Processing ID: Exp_3360\n",
      "341 Processing ID: Exp_3314\n",
      "342 Processing ID: Exp_3362\n",
      "343 Processing ID: Exp_3198\n",
      "344 Processing ID: Exp_3191\n",
      "345 Processing ID: Exp_3207\n",
      "346 Processing ID: Exp_3369\n",
      "347 Processing ID: Exp_3388\n",
      "348 Processing ID: Exp_3348\n",
      "349 Processing ID: Exp_3320\n",
      "350 Processing ID: Exp_3171\n",
      "351 Processing ID: Exp_3254\n",
      "352 Processing ID: Exp_3221\n",
      "353 Processing ID: Exp_3235\n",
      "354 Processing ID: Exp_3240\n",
      "355 Processing ID: Exp_3243\n",
      "356 Processing ID: Exp_3407\n",
      "357 Processing ID: Exp_3252\n",
      "358 Processing ID: Exp_3291\n",
      "359 Processing ID: Exp_3286\n",
      "360 Processing ID: Exp_3273\n",
      "361 Processing ID: Exp_3265\n",
      "362 Processing ID: Exp_3297\n",
      "363 Processing ID: Exp_3414\n",
      "364 Processing ID: Exp_3246\n",
      "365 Processing ID: Exp_3220\n",
      "366 Processing ID: Exp_3413\n",
      "367 Processing ID: Exp_3256\n",
      "368 Processing ID: Exp_3261\n",
      "369 Processing ID: Exp_3350\n",
      "370 Processing ID: Exp_3160\n",
      "371 Processing ID: Exp_3205\n",
      "372 Processing ID: Exp_3163\n",
      "373 Processing ID: Exp_3299\n",
      "374 Processing ID: Exp_3178\n",
      "375 Processing ID: Exp_3278\n",
      "376 Processing ID: Exp_3234\n",
      "377 Processing ID: Exp_3335\n",
      "378 Processing ID: Exp_3199\n",
      "379 Processing ID: Exp_3353\n",
      "380 Processing ID: Exp_3170\n",
      "381 Processing ID: Exp_3371\n",
      "382 Processing ID: Exp_3991\n",
      "383 Processing ID: Exp_4175\n",
      "384 Processing ID: Exp_4172\n",
      "385 Processing ID: Exp_4181\n",
      "386 Processing ID: Exp_4182\n",
      "387 Processing ID: Exp_4183\n",
      "388 Processing ID: Exp_4178\n",
      "389 Processing ID: Exp_4173\n",
      "390 Processing ID: Exp_3993\n",
      "391 Processing ID: Exp_3994\n",
      "392 Processing ID: Exp_3997\n",
      "393 Processing ID: Exp_3998\n",
      "394 Processing ID: Exp_3995\n",
      "395 Processing ID: Exp_3996\n",
      "396 Processing ID: Exp_4185\n",
      "397 Processing ID: Exp_4174\n",
      "398 Processing ID: Exp_3992\n",
      "399 Processing ID: Exp_4030\n",
      "400 Processing ID: Exp_4019\n",
      "401 Processing ID: Exp_4169\n",
      "402 Processing ID: Exp_4037\n",
      "403 Processing ID: Exp_4041\n",
      "404 Processing ID: Exp_4024\n",
      "405 Processing ID: Exp_4045\n",
      "406 Processing ID: Exp_4021\n",
      "407 Processing ID: Exp_4029\n",
      "408 Processing ID: Exp_4042\n",
      "409 Processing ID: Exp_4043\n",
      "410 Processing ID: Exp_4028\n",
      "411 Processing ID: Exp_4034\n",
      "412 Processing ID: Exp_4033\n",
      "413 Processing ID: Exp_4031\n",
      "414 Processing ID: Exp_4032\n",
      "415 Processing ID: Exp_4015\n",
      "416 Processing ID: Exp_4012\n",
      "417 Processing ID: Exp_4009\n",
      "418 Processing ID: Exp_4002\n",
      "419 Processing ID: Exp_4001\n",
      "420 Processing ID: Exp_4013\n",
      "421 Processing ID: Exp_4008\n",
      "422 Processing ID: Exp_4000\n",
      "423 Processing ID: Exp_4006\n",
      "424 Processing ID: Exp_4017\n",
      "425 Processing ID: Exp_4003\n",
      "426 Processing ID: Exp_4004\n",
      "427 Processing ID: Exp_4014\n",
      "428 Processing ID: Exp_4047\n",
      "429 Processing ID: Exp_4046\n",
      "430 Processing ID: Exp_4048\n",
      "431 Processing ID: Exp_4049\n",
      "432 Processing ID: Exp_3999\n",
      "433 Processing ID: Exp_4089\n",
      "434 Processing ID: Exp_4091\n",
      "435 Processing ID: Exp_4078\n",
      "436 Processing ID: Exp_4088\n",
      "437 Processing ID: Exp_4067\n",
      "438 Processing ID: Exp_4070\n",
      "439 Processing ID: Exp_4084\n",
      "440 Processing ID: Exp_4074\n",
      "441 Processing ID: Exp_4081\n",
      "442 Processing ID: Exp_4086\n",
      "443 Processing ID: Exp_4068\n",
      "444 Processing ID: Exp_4075\n",
      "445 Processing ID: Exp_4069\n",
      "446 Processing ID: Exp_4090\n",
      "447 Processing ID: Exp_4066\n",
      "448 Processing ID: Exp_4077\n",
      "449 Processing ID: Exp_4080\n",
      "450 Processing ID: Exp_4082\n",
      "451 Processing ID: Exp_4083\n",
      "452 Processing ID: Exp_4071\n",
      "453 Processing ID: Exp_4145\n",
      "454 Processing ID: Exp_4165\n",
      "455 Processing ID: Exp_4159\n",
      "456 Processing ID: Exp_4167\n",
      "457 Processing ID: Exp_4150\n",
      "458 Processing ID: Exp_4155\n",
      "459 Processing ID: Exp_4140\n",
      "460 Processing ID: Exp_4139\n",
      "461 Processing ID: Exp_4138\n",
      "462 Processing ID: Exp_4132\n",
      "463 Processing ID: Exp_4158\n",
      "464 Processing ID: Exp_4153\n",
      "465 Processing ID: Exp_4161\n",
      "466 Processing ID: Exp_4148\n",
      "467 Processing ID: Exp_4137\n",
      "468 Processing ID: Exp_4160\n",
      "469 Processing ID: Exp_4144\n",
      "470 Processing ID: Exp_4163\n",
      "471 Processing ID: Exp_4146\n",
      "472 Processing ID: Exp_4147\n",
      "473 Processing ID: Exp_4151\n",
      "474 Processing ID: Exp_4156\n",
      "475 Processing ID: Exp_4166\n",
      "476 Processing ID: Exp_4103\n",
      "477 Processing ID: Exp_4098\n",
      "478 Processing ID: Exp_4108\n",
      "479 Processing ID: Exp_4050\n",
      "480 Processing ID: Exp_4130\n",
      "481 Processing ID: Exp_4063\n",
      "482 Processing ID: Exp_4107\n",
      "483 Processing ID: Exp_4101\n",
      "484 Processing ID: Exp_4065\n",
      "485 Processing ID: Exp_4112\n",
      "486 Processing ID: Exp_4141\n",
      "487 Processing ID: Exp_4097\n",
      "488 Processing ID: Exp_4051\n",
      "489 Processing ID: Exp_4093\n",
      "490 Processing ID: Exp_4129\n",
      "491 Processing ID: Exp_4106\n",
      "492 Processing ID: Exp_4095\n",
      "493 Processing ID: Exp_4126\n",
      "494 Processing ID: Exp_4143\n",
      "495 Processing ID: Exp_4135\n",
      "496 Processing ID: Exp_4133\n",
      "497 Processing ID: Exp_4115\n",
      "498 Processing ID: Exp_4096\n",
      "499 Processing ID: Exp_4121\n",
      "500 Processing ID: Exp_4124\n",
      "Overall MSE: 1.3957572670798613\n",
      "Overall MAE: 0.7879959453098248\n",
      "Overall RMSE: 1.1814217143255246\n",
      "Forecast results have been written to forecast_results_2_8020.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load your dataset (assuming it is a CSV file)\n",
    "df = pd.read_csv('phase2_only_records.csv')\n",
    "\n",
    "# Convert 'Date' and 'Hour' columns to a datetime object\n",
    "df['Datetime'] = pd.to_datetime(df['Date']) + pd.to_timedelta(df['Hour'], unit='h')\n",
    "\n",
    "# Set 'Datetime' as index\n",
    "df.set_index('Datetime', inplace=True)\n",
    "exog_vars = ['Temperature']\n",
    "\n",
    "# Prepare a function to fit and forecast using auto_arima for each ID\n",
    "def fit_forecast_arima(df, split_ratio=0.8):\n",
    "    ids = df['ID'].unique()\n",
    "    forecasts = []\n",
    "\n",
    "    for i, id_ in enumerate(ids[:500], start=1):\n",
    "        print(f\"{i} Processing ID: {id_}\")\n",
    "\n",
    "        df_id = df[df['ID'] == id_].sort_index()\n",
    "\n",
    "        # Split the data into train and test\n",
    "        split_index = int(len(df_id) * split_ratio)\n",
    "        train = df_id.iloc[:split_index]\n",
    "        test = df_id.iloc[split_index:]\n",
    "\n",
    "        # Fit the ARIMA model\n",
    "        model = auto_arima(train['Demand_kWh'],\n",
    "                           exogenous=train[exog_vars],\n",
    "                           seasonal=True,\n",
    "                           m=24,  # Assuming daily seasonality with hourly data\n",
    "                           stepwise=True,\n",
    "                           suppress_warnings=True,\n",
    "                           trace=False,\n",
    "                           max_p=2, max_q=2, max_P=1, max_Q=1, max_order=5)\n",
    "\n",
    "        # Forecast\n",
    "        n_periods = len(test)\n",
    "        forecast = model.predict(n_periods=n_periods, exogenous=test[exog_vars])\n",
    "\n",
    "        # Store the forecast and actual values\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'ID': id_,\n",
    "            'Datetime': test.index,\n",
    "            'Actual_Demand': test['Demand_kWh'],\n",
    "            'Predicted_Demand': forecast\n",
    "        })\n",
    "\n",
    "        forecasts.append(forecast_df)\n",
    "\n",
    "    return pd.concat(forecasts)\n",
    "\n",
    "# Run the forecasting function\n",
    "results_df = fit_forecast_arima(df)\n",
    "\n",
    "# Calculate overall error metrics\n",
    "mse = mean_squared_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "mae = mean_absolute_error(results_df['Actual_Demand'], results_df['Predicted_Demand'])\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Overall MSE: {mse}\")\n",
    "print(f\"Overall MAE: {mae}\")\n",
    "print(f\"Overall RMSE: {rmse}\")\n",
    "\n",
    "# Write the results to a file\n",
    "results_df['Date'] = results_df['Datetime'].dt.date\n",
    "results_df['Hour'] = results_df['Datetime'].dt.hour\n",
    "results_df = results_df[['ID', 'Date', 'Hour', 'Actual_Demand', 'Predicted_Demand']]\n",
    "results_df.to_csv('sarima_results_2_8020.csv', index=False)\n",
    "\n",
    "print(\"Forecast results have been written to forecast_results_2_8020.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
